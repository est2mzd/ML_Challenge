



# 図1の左側（エンコーダ部分）についての詳細説明

![fig1](../Images/fig_01.png)

## 1. Input Embedding (入力埋め込み)
- **説明**: エンコーダの最初のステップでは、入力シーケンス（通常は単語やサブワードのシーケンス）が、**入力埋め込み**（Input Embedding）層を通じて固定次元の連続ベクトルに変換されます。これにより、各入力トークンが対応するベクトル表現にマッピングされ、モデルが数値的に処理できる形式に変換されます。

## 2. Positional Encoding (位置エンコーディング)
- **説明**: Transformerにはリカレント構造がないため、シーケンス内のトークンの順序情報を保持する必要があります。これを実現するために、各トークンのベクトルに**位置エンコーディング**（Positional Encoding）が加算されます。位置エンコーディングは、サイン波とコサイン波に基づく関数で生成され、各位置ごとに異なる値が設定されます。これにより、モデルはシーケンス内のトークンの相対的な位置情報を認識することができます。

## 3. Multi-Head Attention (マルチヘッド・アテンション)
- **説明**: **Self-Attention Mechanism**の一種である**マルチヘッド・アテンション**は、エンコーダ内で各トークンがシーケンス全体の他のトークンに対してどの程度「注意」を向けるべきかを計算します。このメカニズムにより、入力シーケンスの異なる部分間の依存関係を捉えることができます。マルチヘッド・アテンションは複数の注意ヘッドを持ち、異なるサブスペースでのAttentionを同時に計算し、それらを結合して出力します。

## 4. Add & Norm (加算と正規化)
- **説明**: 各**マルチヘッド・アテンション**の出力は、元の入力（つまり、位置エンコーディングが加算された入力埋め込み）と**残差接続**（Residual Connection）を介して加算され、その後、**レイヤー正規化**（Layer Normalization）が適用されます。これにより、勾配消失問題を防ぎつつ、学習を安定化させます。

## 5. Feed Forward (フィードフォワード)
- **説明**: 正規化された出力は次に**ポイントワイズ・フィードフォワードネットワーク**（Feed Forward Network）に送られます。このネットワークは、各トークン位置に対して2つの全結合層（線形変換）を適用し、間にReLU活性化関数を使用します。このプロセスにより、非線形性を導入し、各トークンの特徴表現をさらに強化します。

## 6. 再度の Add & Norm
- **説明**: フィードフォワードネットワークの出力は、再度残差接続を通して元の入力と加算され、その後**レイヤー正規化**が適用されます。このステップにより、各トークンの特徴が次の層に渡される前に安定化されます。

## 7. Encoder Stack (エンコーダスタック)
- **説明**: 以上のプロセス（マルチヘッド・アテンション、加算と正規化、フィードフォワード、再度の加算と正規化）が、**エンコーダスタック**内でN回（通常は6回）繰り返されます。各層を通じて、入力シーケンスの特徴が徐々に抽出され、エンコーダ全体で強力なコンテキスト表現が構築されます。このエンコーダスタックの出力は、最終的にデコーダに渡され、次のトークンを予測する際に使用されます。


---



# 図1の右側（デコーダ部分）についての詳細説明

![fig1](../Images/fig_01.png)

## 1. Outputs (Shifted Right) (右シフトされた出力)
- **説明**: デコーダの入力として使用される出力シーケンスは、通常、前の時間ステップで生成されたトークンです。しかし、Transformerでは、自己回帰型のプロセスを確保するために、これらの出力トークンは1つ右にシフトされます（Shifted Right）。この操作により、モデルは現在のステップで予測するトークンが、過去のステップで予測されたトークンのみを参照するようになります。

## 2. Output Embedding (出力埋め込み)
- **説明**: シフトされた出力シーケンスは、**出力埋め込み**（Output Embedding）層を通じて、固定次元の連続ベクトルに変換されます。これにより、各トークンが数値的に処理可能なベクトル表現にマッピングされます。入力埋め込みと同様に、出力埋め込みも学習可能なパラメータとして扱われます。

## 3. Positional Encoding (位置エンコーディング)
- **説明**: 入力側と同様に、デコーダでもトークンの順序情報を保持するために、**位置エンコーディング**（Positional Encoding）が使用されます。出力埋め込みに対して位置エンコーディングが加算され、モデルがシーケンス内のトークンの相対的な位置を認識できるようにします。これにより、トークンの順序に基づく予測が可能になります。

## 4. Masked Multi-Head Attention (マスク付きマルチヘッド・アテンション)
- **説明**: デコーダの最初のサブレイヤーは、**マスク付きマルチヘッド・アテンション**（Masked Multi-Head Attention）です。この層では、未来の情報に対する注意を防ぐため、未来の位置に対応するトークンへのAttentionがマスクされます。これにより、デコーダは過去および現在のトークンにのみ注意を向け、次のトークンを予測します。

## 5. Add & Norm (加算と正規化)
- **説明**: マスク付きマルチヘッド・アテンションの出力は、残差接続を通じて元の入力と加算され、その後**レイヤー正規化**（Layer Normalization）が適用されます。この操作により、勾配消失を防ぎつつ、安定した学習が可能となります。

## 6. Encoder-Decoder Attention (エンコーダ-デコーダ・アテンション)
- **説明**: 次のサブレイヤーでは、**エンコーダ-デコーダ・アテンション**が適用されます。この層では、デコーダの出力がクエリとして使用され、エンコーダの出力がキーおよびバリューとして使用されます。これにより、デコーダはエンコーダの出力に対して注意を向け、入力シーケンスの情報を考慮しながら次のトークンを生成することができます。

## 7. Add & Norm (加算と正規化)
- **説明**: エンコーダ-デコーダ・アテンションの出力も、再度残差接続を通じて元の入力と加算され、**レイヤー正規化**が適用されます。これにより、アテンション操作が安定し、次の処理ステップに渡されます。

## 8. Feed Forward (フィードフォワード)
- **説明**: 正規化された出力は、**フィードフォワードネットワーク**（Feed Forward Network）に送られます。このネットワークは、各トークン位置に対して独立に2つの全結合層を適用し、ReLU活性化関数を用いて非線形性を導入します。この層により、各トークンの特徴がさらに強化されます。

## 9. 再度の Add & Norm
- **説明**: フィードフォワードネットワークの出力は、再度残差接続を通して元の入力と加算され、**レイヤー正規化**が適用されます。これにより、最終的なデコーダ
