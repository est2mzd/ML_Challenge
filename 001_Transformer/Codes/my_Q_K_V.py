'''
1. クエリ (Query):
  ここでは、赤い色を持つ商品を探している顧客の要望を表現しています。[1.0, 0.0, 0.0, 0.5] というベクトルは、Red=1.0(赤)、Green=0.0(緑)、Blue=0.0(青)、Weight=0.5(重量0.5kg)を表しています。顧客は赤い商品で、重さが0.5kg程度のものを探しています。

2.キー (Key):
  倉庫にある商品の特徴ベクトルです。ここでは、3つの商品があり、それぞれの特徴が keys に対応します。例えば、[1.0, 0.0, 0.0, 0.4] は、赤い色で重さが0.4kgの商品を表しています。

3. バリュー (Value):
  各キーに対応する商品に関連する情報を表します。ここでは、各商品の価格がバリューとして設定されています。例えば、[100.0] は、最初の商品が100ドルであることを表しています。

4. クエリとキーの類似度を計算:
  クエリと各キーの内積を計算することで、クエリ(顧客が探している商品)とキー(倉庫にある商品)の間の類似度を求めます。類似度が高いほど、クエリとキーが似ている(つまり、顧客の要望に近い商品)ということになります。

5. スケーリング:
  類似度スコアを、キーの次元数(ここでは4)の平方根で割ってスケーリングします。これにより、類似度スコアの値が過度に大きくなるのを防ぎ、勾配爆発を抑えます。

6.ソフトマックス関数で正規化:
  スケーリングされた類似度スコアにソフトマックス関数を適用し、注意の重みを計算します。これにより、すべてのキーに対する注意の重みが0から1の間の値になり、総和が1になるように正規化されます。注意の重みが大きいほど、クエリと対応するキーの関連性が高いことを意味します。

7.バリューに注意の重みを適用:
  最後に、得られた注意の重みを各バリューに掛け合わせて、出力を計算します。これにより、クエリに最も関連性の高い商品の情報が強調されて反映されます。具体的には、類似度が高い商品の価格が重み付けされ、最終的な出力が計算されます。

<実行結果の解釈>

- Similarity Scores:
  それぞれの商品の特徴とクエリの特徴ベクトル間の類似度を示します。

- Scaled Scores:
  類似度スコアをスケーリングしたものです。

- Attention Weights:
  各商品の価格にどれだけ注意を向けるべきかを示す重みです。重みが高いほど、その商品の特徴がクエリに近いことを意味します。

-Weighted Value (Output):
  最終的に、注意の重みを反映させたバリューの合計です。これは、顧客が探している商品に最も関連する価格情報を表しています。

<まとめ>
  このプログラムは、クエリ(顧客の要望)、キー(倉庫の商品)、バリュー(商品の価格)を使って、顧客の要望に最も適した商品の情報を抽出する例を示しています。各ステップは、Transformerモデルにおける自己注意機構の具体的な計算を反映しており、クエリとキーの類似度に基づいて、バリューを適切に重み付けして出力を生成します。
'''


import torch
import torch.nn.functional as F

# クエリ、キー、バリューの定義
# ここでは、物理的に意味のある値として、異なる商品の特徴ベクトルを考えます。

# 商品の特徴量: 色 (Red, Green, Blue) と重さ (Weight)
# クエリ: 検索したい商品の特徴(例えば、赤い商品を探している)
query = torch.tensor([[1.0, 0.0, 0.0, 0.5]])  # (Red=1, Green=0, Blue=0, Weight=0.5) 

# キー: 倉庫にある商品の特徴(例えば、3つの商品がある)
keys = torch.tensor([
    [1.0, 0.0, 0.0, 0.4],  # 商品1: 赤い色、少し軽い (Red=1, Green=0, Blue=0, Weight=0.4)
    [0.0, 1.0, 0.0, 0.6],  # 商品2: 緑色、少し重い (Red=0, Green=1, Blue=0, Weight=0.6)
    [1.0, 0.0, 0.0, 0.7]   # 商品3: 赤い色、少し重い (Red=1, Green=0, Blue=0, Weight=0.7)
])  # サイズ: (3, 4)

# バリュー: キーに対応する商品の価格(例えば、商品の値段を意味する)
values = torch.tensor([
    [100.0],  # 商品1の価格
    [200.0],  # 商品2の価格
    [150.0]   # 商品3の価格
])  # サイズ: (3, 1)

# クエリとキーの類似度を計算 (内積を取る)
similarity_scores = torch.matmul(query, keys.T)  # サイズ: (1, 3)
print(f"Similarity Scores: {similarity_scores}")

# スケーリング (キーの次元数の平方根で割る)
d_k = keys.size(1)  # キーの次元数 (この場合は4)
scaled_scores = similarity_scores / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))
print(f"Scaled Scores: {scaled_scores}")

# ソフトマックス関数で正規化して注意の重みを得る
attention_weights = F.softmax(scaled_scores, dim=-1)  # サイズ: (1, 3)
print(f"Attention Weights: {attention_weights}")

# 注意の重みをバリューに適用する
weighted_values = torch.matmul(attention_weights, values)  # サイズ: (1, 1)
print(f"Weighted Value (Output): {weighted_values}")
